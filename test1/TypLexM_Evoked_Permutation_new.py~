"""
=================================================================
Permutation t-test on source data with spatio-temporal clustering
=================================================================

Tests if the evoked response is significantly different between
conditions across subjects (simulated here using one subject's data).
The multiple comparisons problem is addressed with a cluster-level
permutation test across space and time.

"""

# Authors: Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>
#          Eric Larson <larson.eric.d@gmail.com>
# License: BSD (3-clause)

print(__doc__)
# Russell's addition
import sys
sys.path.append('/imaging/local/software/python_packages/nibabel/1.3.0')
sys.path.append('/imaging/local/software/python_packages/pysurfer/v0.4')
# End

# for qsub
# (add ! here if needed) /imaging/local/software/anaconda/latest/x86_64/bin/python
sys.path.append('/imaging/local/software/mne_python/git-master-0.8/mne-python/')
###


import os.path as op
import numpy as np
from numpy.random import randn
from scipy import stats as stats

import mne
from mne import (io, spatial_tris_connectivity, compute_morph_matrix,
                 grade_to_tris)
from mne.epochs import equalize_epoch_counts
from mne.stats import (spatio_temporal_cluster_1samp_test,
                       summarize_clusters_stc)
from mne.minimum_norm import apply_inverse, read_inverse_operator
from mne.datasets import sample
from mne.viz import mne_analyze_colormap

###############################################################################
# Set parameters
out_path = '/imaging/rf02/TypLexMEG/icaanalysis_results/stc/permutation/evoked/' # root
data_path = '/imaging/rf02/TypLexMEG/'	# where subdirs for MEG data are
inv_path = '/imaging/rf02/TypLexMEG/'
inv_fname = 'InverseOperator_fft_1_48_clean_ica_EMEG-inv.fif'
event_path = '/group/erp/data/olaf.hauk/MEG/TypLexM/data/MF22_new/'
print sys.argv
subject_inds = []
for ss in sys.argv[1:]:
 subject_inds.append( int( ss ) )

subject_inds=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]
print "subject_inds:"
print subject_inds
print "No rejection"

list_all = ['meg10_0378/101209/', 
'meg10_0390/101214/',
'meg11_0026/110223/', 
'meg11_0050/110307/', 
'meg11_0052/110307/', 
'meg11_0069/110315/', 
'meg11_0086/110322/', 
'meg11_0091/110328/', 
'meg11_0096/110404/', 
'meg11_0101/110411/', 
'meg11_0102/110411/', 
'meg11_0112/110505/',
'meg11_0104/110412/',  
'meg11_0118/110509/', 
'meg11_0131/110519/', 
'meg11_0144/110602/', 
'meg11_0147/110603/'
]
# subjects names used for MRI data
subjects=['SS1_Meg10_0378',
'SS2_Meg10_0390',
'SS3_Meg11_0026',
'SS4_Meg11_0050',
'SS5_Meg11_0052',
'SS6_Meg11_0069',
'SS9_Meg11_0086',
'SS10_Meg11_0091',
'SS12_Meg11_0096',
'SS13_Meg11_0101',
'SS14_Meg11_0102',
'SS15_Meg11_0112',
'SS16_Meg11_0104',
'SS18_Meg11_0118',
'SS19_Meg11_0131',
'SS20_Meg11_0144',
'SS21_Meg11_0147'
]

ll = []
for ss in subject_inds:
 ll.append(list_all[ss])

print "ll:"
print ll
n_subjects=17
stim_delay = 0.034 # delay in s ((NOTE! not in the example, taken from Olaf's script. Rezvan))
tmin, tmax = -0.5, 0.7
event_ids = {'cncrt_wrd': 1, 'abs_wrd': 2}
X=np.zeros((20484,2, 17))
for ii, meg in enumerate(ll):
	print ii
	fname_cncrt = data_path + meg + 'Morphed_SemLoc_icaclean_Concrete_Source_Evoked_m500_700'
	stc_cncrt = mne.read_source_estimate(fname_cncrt)
	#abslt_cncrt= np.absolute(stc_cncrt.copy().crop(.3,.4).data)
	fname_abs = data_path + meg + 'Morphed_SemLoc_icaclean_Abstract_Source_Evoked_m500_700'
	stc_abs = mne.read_source_estimate(fname_abs)
	#    Let's only deal with t > 0, cropping to reduce multiple comparisons
	stc_subtract=np.subtract(stc_cncrt,stc_abs)
	b2=0.25
	for cc in range(1):
		b1=b2+0.001; b2=b1+0.1-0.001
	 	X[:,cc,ii]=np.subtract(np.abs(stc_cncrt.copy().crop(b1,b2).mean().data.squeeze()),np.abs(stc_abs.copy().crop(b1,b2).mean().data.squeeze()))#stc_subtract.copy().crop(b1,b2).mean().data.squeeze()
	tmin = stc_subtract.tmin
	tstep = stc_subtract.tstep
	X[:,1,:]=X[:,0,:].copy()
	###############################################################################
	print "transform to common cortical space"

	#    Normally you would read in estimates across several subjects and morph
	#    them to the same cortical space (e.g. fsaverage). For example purposes,
	#    we will simulate this by just having each "subject" have the same
	#    response (just noisy in source space) here. Note that for 7 subjects
	#    with a two-sided statistical test, the minimum significance under a
	#    permutation test is only p = 1/(2 ** 6) = 0.015, which is large.
	
	#    It's a good idea to spatially smooth the data, and for visualization
	#    purposes, let's morph these to fsaverage, which is a grade 5 source space
	#    with vertices 0:10242 for each hemisphere. Usually you'd have to morph
	#    each subject's data separately (and you might want to use morph_data
	#    instead), but here since all estimates are on 'sample' we can use one
	#    morph matrix for all the heavy lifting.

	#    Finally, we want to compare the overall activity levels in each condition,
	#    the diff is taken along the last axis (condition). The negative sign makes
	#    it so condition1 > condition2 shows up as "red blobs" (instead of blue).
print('Computing connectivity.')
connectivity = spatial_tris_connectivity(grade_to_tris(5))
fsave_vertices = [np.arange(10242), np.arange(10242)]
n_permutations=1024

#    Note that X needs to be a multi-dimensional array of shape
#    samples (subjects) x time x space, so we permute dimensions
X = np.transpose(X, [2, 1, 0])

#    Now let's actually do the clustering. This can take a long time...
#    Here we set the threshold quite high to reduce computation.
p_threshold = 0.01
t_threshold = -stats.distributions.t.ppf(p_threshold /2., n_subjects - 1)#dict(start=0, step=1)#
#t_threshold=2
print('Clustering.')
T_obs, clusters, cluster_p_values, H0 = clu = spatio_temporal_cluster_1samp_test(X, connectivity=connectivity, n_jobs=2, threshold=t_threshold)#, max_step=0)#
#    Now select the clusters that are sig. at p < 0.05 (note that this value
#    is multiple-comparisons corrected).
good_cluster_inds = np.where(cluster_p_values <0.05)[0]
print cluster_p_values.min(); print good_cluster_inds
###############################################################################
# Visualize the clusters

print('Visualizing clusters.')

#    Now let's build a convenient representation of each cluster, where each
#    cluster becomes a "time point" in the SourceEstimate
stc_all_cluster_vis = summarize_clusters_stc(clu, tstep=0.05, vertno=fsave_vertices, subject='avgsubj', p_thresh=0.05)

out_file1=out_path + 'Permutation_clusterp05_p05_17subj_SemLoc_icaclean_MEG_1_48_ConcreteAbstract_250_350_maxstep0_noneqlizedEvokednew'
stc_all_cluster_vis.save(out_file1)
"""
Matx=np.zeros((20484,4))
T=np.divide(T_obs,np.absolute(T_obs))
for cc in range(good_cluster_inds.shape[0]):
	Matx[clusters[good_cluster_inds[cc]][1],clusters[good_cluster_inds[cc]][0]]=T[clusters[good_cluster_inds[cc]][0],clusters[good_cluster_inds[cc]][1]]
	

#aa=Matx[clusters[good_cluster_inds[cc]][1],clusters[good_cluster_inds[cc]][0]]
#bb=T_obs[clusters[good_cluster_inds[cc]][0],clusters[good_cluster_inds[cc]][1]]<0
#aa[bb]=-1
#Matx[clusters[good_cluster_inds[cc]][1],clusters[good_cluster_inds[cc]][0]]=aa

tmin1=50
tstep1=100
vertices_to = [np.arange(10242), np.arange(10242)]
matx_stc = mne.SourceEstimate(Matx, vertices=vertices_to,tmin=1e-3 * tmin1, tstep=1e-3 * tstep1, subject='avgsubj')
out_file2=out_path + 'Permutation_stepwise_clusterp05_p05_17subj_SemLoc_icaclean_MEG_1_48_ConcreteAbstract_200_500_100ms_maxstep0_noneqlizedEvokednew'
matx_stc.save(out_file2)
"""
